<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="style.css">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Latency Matters: Real-Time Action Forecasting Transformer</title>
</head>
<body class="h-100 d-flex flex-column">
    <main class="container flex-grow-1">
        <header class="py-3">
            <h2 class="custom-title mt-3">
                Latency Matters: Real-Time Action Forecasting Transformer
            </h2>
            <div class="authors custom-text mt-3">
                <div class="px-2">
                    <a href="https://www.linkedin.com/in/harshayu-girase-764b06153">Harshayu Girase</a>
                    <span><sup>1,2</sup>*</span>
                </div>
                <div class="px-2">
                    <a href="https://lukan94.github.io/">Nakul Agarwal</a>
                    <sup>1</sup>
                </div>
                <div class="px-2">
                    <a href="https://chihochoi.github.io/">Chiho Choi</a>
                    <sup>1</sup>
                </div>
                <div class="px-2">
                    <a href="https://karttikeya.github.io/">Karttikeya Mangalam</a>
                    <span><sup>2</sup>*</span>
                </div>
            </div>
            <div class="mt-1">
                <p><small>* denotes equal technical contribution</small></p>
            </div>
            <div class="insts custom-text mt-1">
                <div class="px-2"><sup>1</sup>Honda Research Institute USA</div>
                <div class="px-2"><sup>2</sup>UC Berkeley</div>
            </div>
            <div class="mt-4 mb-2">
                <span class="mx-1">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf" class="btn btn-dark rounded-pill">
                      <i class="fas fa-file-pdf"></i>
                      <span>Paper</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="https://www.youtube.com/watch?v=0tbK36hzSM0" class="btn btn-dark rounded-pill">
                      <i class="fab fa-youtube"></i>
                      <span>Video</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="fab fa-github"></i>
                      <span>Code</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="fas fa-chalkboard"></i>
                      <span>Slides</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="far fa-clipboard"></i>
                      <span>Poster</span>
                    </a>
                </span>
            </div>
        </header>
        <div style="max-width:70%;margin:auto">
            <section id="new">
                <h3 class="text-center mt-4 mb-2">
                    Bigger Models are <u>NOT</u> Necessarily Better
                </h3>
                <p class="text-justify">
                    In this paper, we propose a new real-time setting for evaluating action forecasting networks where bigger is not necessarily better.
                    We propose a latency-aware real-time evaluation setting that better mimics practical deployment 
                    settings for embodied forecasting systems. Real-time evaluation demonstrates a clear trade-off between 
                    inference latency and model forecasting fidelity, paving the path for the development of latency-aware 
                    forecasting models in the future.
                </p>
                <div class="row px-1 my-2">
                    <div class="col"></div>
                    <div class="border custom-rounded col-7"><img src="images/tradeoff.png" alt="" style="max-width:100%"></div>
                    <div class="col"></div>
                </div>
                <p class="text-justify">
                    The graph on the right shows the trade-off between latency and high-fidelity forecasts in the real-time evaluation 
                    setting. Bigger models continue to perform better in latency agnostic offline settings. When latency is accounted 
                    for, bigger models with higher latency drop in forecasting performance because the model is unable to access more  
                    recent data.
                </p>
                <div class="row px-1 my-2">
                    <div class="col"></div>
                    <div class="border custom-rounded col-6"><img src="images/real-time-eval.png" alt="" style="max-width:100%"></div>
                    <div class="col"></div>
                </div>
                <p class="text-justify">
                    The diagram on the left details the difference between offline and real-time evaluation. During offline evaluation, 
                    inference latency is assumed to be zero, allowing predictions to be made at any time step using all prior frames up to the 
                    forecasting horizon. During real-time evaluation, the nonzero inference latency of the model must be accounted for. In this 
                    setting, predictions must be made using frames further in the past. The reduced latency of RAFTformer allows it to use 
                    significantly more recent frames than prior methods.
                </p>
            </section>
            <section id="video">
                <h3 class="text-center mt-4 mb-2">
                    Video
                </h3>
                <div class="row px-1 my-2">
                    <div class="col"></div>
                    <div class="border-0 custom-rounded embed-responsive embed-responsive-16by9 col-10">
                        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/0tbK36hzSM0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
            <section id="abstract">
                <div class="row mt-4">
                    <div class="col"></div>
                    <div class="col-10 border-0 custom-rounded bg-dark">
                        <div class="row">
                            <div class="col"></div>
                            <a class="col btn-dropdown" id="dropdown-container" data-toggle="collapse" href="#collapseAbstract" role="button" aria-expanded="false" aria-controls="collapseExample">
                                <i class="fas fa-caret-down fa-2xs" id="caret-icon"></i>
                                <span>Abstract</span>
                            </a>
                            <div class="col"></div>
                        </div>
                        <div class="collapse" id="collapseAbstract">
                            <p class="text-justify text-light mx-2 mb-4">
                                We present RAFTformer, a real-time action forecasting transformer for latency-aware real-world action forecasting. 
                                RAFTformer is a two-stage fully transformer based architecture comprising of a video transformer backbone that 
                                operates on high resolution, short-range clips, and a head transformer encoder that temporally aggregates 
                                information from multiple short-range clips to span a long-term horizon. Additionally, we propose a novel 
                                self-supervised shuffled causal masking scheme as a model level augmentation to improve forecasting fidelity. 
                                Finally, we also propose a novel real-time evaluation setting for action forecasting that directly couples model 
                                inference latency to overall forecasting performance and brings forth a hitherto overlooked trade-off between 
                                latency and action forecasting performance. Our parsimonious network design facilitates RAFTformer inference latency 
                                to be 9x smaller than prior works at the same forecasting accuracy. Owing to its two-staged design, RAFTformer uses 
                                94% less training compute and 90% lesser training parameters to outperform prior state-of-the-art baselines by 4.9 
                                points on EGTEA Gaze+ and by 1.4 points on EPIC-Kitchens100 validation set, as measured by Top-5 recall (T5R) in the 
                                offline setting. In the real-time setting, RAFTformer outperforms prior works by an even greater margin of up to 4.4 
                                T5R points on the EPIC-Kitchens-100 dataset.
                            </p>
                        </div>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
            <section id="fyi">
                <p class="mt-4">
                    We also introduce RAFTformer, an architecture that beats prior state-of-the-art action forecasting methods with a huge reduction 
                    in latency. For more about this, see the paper.
                </p>
            </section>
        </div>
        <section id="BibTeX" style="max-width:80%;margin:auto">
            <div class="container is-max-desktop content">
                <h3 class="text-center mt-4 mb-2">
                    BibTeX
                </h3>
                <pre class="bibtex p-3"><code>@inproceedings{girase2023latency,
    title     = {Latency Matters: Real-Time Action Forecasting Transformer},
    author    = {Girase, Harshayu and Agarwal, Nakul and Choi, Chiho and Mangalam, Karttikeya},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages     = {18759--18769},
    year      = {2023}
}</code></pre>
            </div>
        </section>
    </main>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>
    <script src="https://kit.fontawesome.com/3aef636b73.js" crossorigin="anonymous"></script>
    <script src="script.js"></script>
</body>
</html>