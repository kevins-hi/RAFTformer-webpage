<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Noto Sans" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Google Sans" rel="stylesheet">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Latency Matters: Real-Time Action Forecasting Transformer</title>
</head>
<body class="h-100 d-flex flex-column dark-bg custom-light">
    <main class="container flex-grow-1">
        <header class="py-3">
            <h2 class="custom-title text-light mt-3">
                Latency Matters: Real-Time Action Forecasting Transformer
            </h2>
            <div class="authors mt-3">
                <div class="px-3">
                    <a href="https://www.linkedin.com/in/harshayu-girase-764b06153">Harshayu Girase</a>
                    <span><sup>1,2</sup>*</span>
                </div>
                <div class="px-3">
                    <a href="https://lukan94.github.io/">Nakul Agarwal</a>
                    <sup>1</sup>
                </div>
                <div class="px-3">
                    <a href="https://chihochoi.github.io/">Chiho Choi</a>
                    <sup>1</sup>
                </div>
                <div class="px-3">
                    <a href="https://karttikeya.github.io/">Karttikeya Mangalam</a>
                    <span><sup>2</sup>*</span>
                </div>
            </div>
            <div class="mt-1">
                <span><small>* denotes equal technical contribution</small></span>
            </div>
            <div class="insts custom-text mt-1">
                <div class="px-2"><sup>1</sup>Honda Research Institute USA</div>
                <div class="px-2"><sup>2</sup>UC Berkeley</div>
            </div>
            <div class="mt-3">
                <span class="mx-1">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf" class="btn btn-dark rounded-pill">
                      <i class="fas fa-file-pdf"></i>
                      <span>Paper</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="https://www.youtube.com/watch?v=0tbK36hzSM0" class="btn btn-dark rounded-pill">
                      <i class="fab fa-youtube"></i>
                      <span>Video</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="fab fa-github"></i>
                      <span>Code</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="fas fa-chalkboard"></i>
                      <span>Slides</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="far fa-clipboard"></i>
                      <span>Poster</span>
                    </a>
                </span>
            </div>
        </header>
        <div style="max-width:70%;margin:auto">
            <section id="new">
                <h3 class="text-center text-light headline mt-5 mb-3">
                    Bigger Models are <u>NOT</u> Necessarily Better
                </h3>
                <p class="text-justify">
                    In this paper, we propose a <i>new real-time setting</i> for evaluating action forecasting networks where bigger is not 
                    necessarily better. Current state-of-the-art methods trend towards increasing model size for higher fidelity forecasts, 
                    ignoring the cost of increased latency. The new latency-aware real-time setting better mimics practical deployment settings 
                    for embodied forecasting systems, paving the path for the development of latency-aware forecasting models in the future.
                </p>
                <div class="row px-1 my-3">
                    <div class="col"></div>
                    <div class="col-7"><img class="border-0 custom-rounded" src="images/tradeoff.png" alt="" style="max-width:100%"></div>
                    <div class="col"></div>
                </div>
                <p class="text-justify">
                    The graph above shows a clear trade-off between latency and high-fidelity forecasts in the real-time evaluation setting.
                    While bigger models continue to perform better in latency agnostic offline settings, in the real-time setting, high 
                    latency models drop in forecasting performance because the model is unable to access more recent data.
                </p>
            </section>
            <section id="video">
                <h3 class="text-center text-light mt-4 mb-2">
                    Video
                </h3>
                <div class="row px-1 my-2">
                    <div class="col"></div>
                    <div class="border-0 custom-rounded embed-responsive embed-responsive-16by9 col-10">
                        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/0tbK36hzSM0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
            <section id="diagram">
                <div class="row px-1 mt-4 mb-3">
                    <div class="col"></div>
                    <div class="col-7"><img class="border-0 custom-rounded" src="images/real-time-eval.png" alt="" style="max-width:100%"></div>
                    <div class="col"></div>
                </div>
                <p class="text-justify">
                    This diagram details the difference between offline and real-time evaluation. During offline evaluation, 
                    inference latency is assumed to be zero, allowing predictions to be made at any time step using all prior frames up to the 
                    forecasting horizon. During real-time evaluation, the nonzero inference latency of the model must be accounted for. In this 
                    setting, predictions must be made using frames further in the past. A model with reduced latency is able to leverage 
                    significantly more recent frames than prior methods, leading to more accurate predictions.
                </p>
            </section>
            <section id="abstract">
                <div class="row mt-4">
                    <div class="col"></div>
                    <div class="col-10 border-0 custom-rounded bg-dark">
                        <div class="row">
                            <div class="col"></div>
                            <a class="col btn-dropdown" id="dropdown-container" data-toggle="collapse" href="#collapseAbstract" role="button" aria-expanded="false" aria-controls="collapseAbstract">
                                <i class="fas fa-caret-down fa-2xs" id="caret-icon"></i>
                                <span>Abstract</span>
                            </a>
                            <div class="col"></div>
                        </div>
                        <div class="collapse" id="collapseAbstract">
                            <p class="text-justify mx-2 mb-4">
                                We present RAFTformer, a real-time action forecasting transformer for latency-aware real-world action forecasting. 
                                RAFTformer is a two-stage fully transformer based architecture comprising of a video transformer backbone that 
                                operates on high resolution, short-range clips, and a head transformer encoder that temporally aggregates 
                                information from multiple short-range clips to span a long-term horizon. Additionally, we propose a novel 
                                self-supervised shuffled causal masking scheme as a model level augmentation to improve forecasting fidelity. 
                                Finally, we also propose a novel real-time evaluation setting for action forecasting that directly couples model 
                                inference latency to overall forecasting performance and brings forth a hitherto overlooked trade-off between 
                                latency and action forecasting performance. Our parsimonious network design facilitates RAFTformer inference latency 
                                to be 9x smaller than prior works at the same forecasting accuracy. Owing to its two-staged design, RAFTformer uses 
                                94% less training compute and 90% lesser training parameters to outperform prior state-of-the-art baselines by 4.9 
                                points on EGTEA Gaze+ and by 1.4 points on EPIC-Kitchens100 validation set, as measured by Top-5 recall (T5R) in the 
                                offline setting. In the real-time setting, RAFTformer outperforms prior works by an even greater margin of up to 4.4 
                                T5R points on the EPIC-Kitchens-100 dataset.
                            </p>
                        </div>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
            <section id="fyi">
                <p class="mt-4">
                    We also introduce RAFTformer, an architecture that beats prior state-of-the-art action forecasting methods with a huge reduction 
                    in latency. For more about this, see the paper.
                </p>
            </section>
        </div>
        <section id="BibTeX" style="max-width:80%;margin:auto">
            <div class="container is-max-desktop content">
                <h3 class="text-center text-light mt-4 mb-2">
                    BibTeX
                </h3>
                <pre class="bibtex p-3 bg-dark text-light border-0 custom-rounded"><code>@inproceedings{girase2023latency,
    title     = {Latency Matters: Real-Time Action Forecasting Transformer},
    author    = {Girase, Harshayu and Agarwal, Nakul and Choi, Chiho and Mangalam, Karttikeya},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages     = {18759--18769},
    year      = {2023}
}</code></pre>
            </div>
        </section>
    </main>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>
    <script src="https://kit.fontawesome.com/3aef636b73.js" crossorigin="anonymous"></script>
    <script src="script.js"></script>
</body>
</html>